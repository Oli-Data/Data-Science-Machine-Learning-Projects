{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** <br> <ul> <li> Do **NOT** replace or remove this notebook (ipynb file)! Each cell has unique nbgrader's metadata and ID which, if changed outside the nbgrader, cannot pass the tests. Do **NOT** change the name of the file!</li> <li> To receive any credit, don't forget to **SUBMIT** your notebook when you are done! You can have multiple submissions before the deadline; only the last one is saved, including its timestamp.</li> <li>Before submitting, **Validate** your notebook to check if your codes pass all visible tests. </li> <li>Make sure you fill in any cell with the comment `# your code here`. Remove or comment the command `fail()` (in R), or `raise NotImplementedError` (in Python) and place your code there </li> </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Christian Olivares-Rodriguez\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f5cbe71c264320787386cf4ee540d3c",
     "grade": false,
     "grade_id": "cell-01be3d62fd71820d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART 1: Naive Bayes in Python\n",
    "\n",
    "\n",
    "- We will implement Naive Bayes in Python using built-in Scikit-Learn methods in the first part of this homework.\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's start by importing libraries. Run the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd23abd0e2f822bb000a02856235ec9d",
     "grade": false,
     "grade_id": "cell-b3a0c838c3874782",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encoding categorical features from strings to number arrays\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a49a83314880630582fd97dfa809392",
     "grade": false,
     "grade_id": "cell-0ba8909335e40e15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Read in and quick look at the data \n",
    "\n",
    "<br>\n",
    "\n",
    "We use the dataset `Heart.csv`, from *An Introduction to Statistical Learning with Applications in R* (ISLR): <https://www.statlearning.com>. <br>\n",
    "\n",
    "Run the following cell to explore the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fbcf0559572c3738b42658b7106214c",
     "grade": false,
     "grade_id": "cell-914441ee0eaf607c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  \\\n",
       "0          1   63    1       typical     145   233    1        2    150   \n",
       "1          2   67    1  asymptomatic     160   286    0        2    108   \n",
       "2          3   67    1  asymptomatic     120   229    0        2    129   \n",
       "3          4   37    1    nonanginal     130   250    0        0    187   \n",
       "4          5   41    0    nontypical     130   204    0        2    172   \n",
       "\n",
       "   ExAng  Oldpeak  Slope   Ca        Thal  AHD  \n",
       "0      0      2.3      3  0.0       fixed   No  \n",
       "1      1      1.5      2  3.0      normal  Yes  \n",
       "2      1      2.6      2  2.0  reversable  Yes  \n",
       "3      0      3.5      3  0.0      normal   No  \n",
       "4      0      1.4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Heart.csv', sep=',')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ebf9fa1fb3cc918d5a6bcbaca6e28d3",
     "grade": false,
     "grade_id": "cell-f5fe4160f1c994a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Each row (i.e. observation) represents a single patient. The last variable, `AHD`, is binary (Yes/No) and indicates whether there is angiographic evidence of heart disease. This variable is our output categorical variable. All other variables except the first one (PatientID) are our predictors/features.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Goal\n",
    "\n",
    "Our goal is to use the Naive Bayes method to classify patients by the `AHD` label. That is, based on the predictor variables (features), we want to predict whether the patient has angiographic heart disease (`AHD = \"Yes\"`) or not (`AHD = \"No\"`).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "872f8b6ba79c8ac3953ce09a58a28536",
     "grade": false,
     "grade_id": "cell-1424dac770731dbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data munging and cleaning\n",
    "\n",
    "<br>\n",
    "\n",
    "The variable `PatientID` is not a predictor, so we remove it from our data frame `df`.\n",
    "\n",
    "We can use, for example, the `pandas` method `drop()` to drop\n",
    "\n",
    "`df = df.drop(columns = ??)`,\n",
    "\n",
    "or `iloc()` to extract needed data:\n",
    "\n",
    "`df = df.iloc[??, ??]`\n",
    "\n",
    "Simply run the following to drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a081890c612060846aece8ec5437275",
     "grade": false,
     "grade_id": "cell-c9ba5199f5754e4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
       "0   63    1       typical     145   233    1        2    150      0      2.3   \n",
       "1   67    1  asymptomatic     160   286    0        2    108      1      1.5   \n",
       "2   67    1  asymptomatic     120   229    0        2    129      1      2.6   \n",
       "3   37    1    nonanginal     130   250    0        0    187      0      3.5   \n",
       "4   41    0    nontypical     130   204    0        2    172      0      1.4   \n",
       "\n",
       "   Slope   Ca        Thal  AHD  \n",
       "0      3  0.0       fixed   No  \n",
       "1      2  3.0      normal  Yes  \n",
       "2      2  2.0  reversable  Yes  \n",
       "3      3  0.0      normal   No  \n",
       "4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"PatientID\"])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0f8d41252914458dff86ce9f3b2ddab",
     "grade": false,
     "grade_id": "cell-c48d8302a8480021",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Train/Test Split\n",
    "\n",
    "As usual, we should perform a train/test split. The following cell does just this. We could, and usually do, simply use `train_test_split` from `sklearn.model_selection`, but let's mix it up a bit just as a reminder of the process.\n",
    "\n",
    "As a result, we get `train_df` and `test_df`. These DataFrames contain both our features and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cb449ab81898ceb8fb9664c55ca16ed",
     "grade": false,
     "grade_id": "cell-e0888b3d0aa3f69b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 14)\n",
      "(91, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>152</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>135</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
       "0   56    0    nontypical     140   294    0        2    153      0      1.3   \n",
       "1   44    1  asymptomatic     120   169    0        0    144      1      2.8   \n",
       "2   42    1    nonanginal     130   180    0        0    150      0      0.0   \n",
       "3   40    1  asymptomatic     152   223    0        0    181      0      0.0   \n",
       "4   63    0    nonanginal     135   252    0        2    172      0      0.0   \n",
       "\n",
       "   Slope   Ca        Thal  AHD  \n",
       "0      2  0.0      normal   No  \n",
       "1      3  0.0       fixed  Yes  \n",
       "2      1  0.0      normal   No  \n",
       "3      1  0.0  reversable  Yes  \n",
       "4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell performs a train/test split\n",
    "#####\n",
    "\n",
    "# set seed\n",
    "np.random.seed(123)\n",
    "\n",
    "# Randomize the DataFrame (i.e. shuffle the rows); \n",
    "df_randomized = df.sample(frac=1)  #could also set seed by argument random_state=123\n",
    "\n",
    "# Calculate index for split (size of train data) -take first 70% of the data for training set\n",
    "N = round(len(df_randomized) * 0.7)\n",
    "\n",
    "# Split into training and test dataframes\n",
    "# We can throw in reseting the index as well; drop=True means don't keep the old index as a column\n",
    "train_df = df_randomized[:N].reset_index(drop=True)\n",
    "\n",
    "test_df = df_randomized[N:].reset_index(drop=True)\n",
    "\n",
    "# Check the shapes of our new dataframes\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "# Can confirm that setting the random number seed makes results reproducible by running this cell a few times:\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d00d3bde3ac46aba46a8c03b1f11991c",
     "grade": false,
     "grade_id": "cell-e843eb7fca0a6c1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Imputation\n",
    "\n",
    "We have a handful of missing values in our dataframe. Recall our three basic options for dealing with missing data:\n",
    "\n",
    "1. Drop the missing observations\n",
    "   - `drop()`\n",
    "2. Drop the whole attribute\n",
    "   - `dropna()`\n",
    "3. Impute the missing values to something else. Common choices = 0, mean/median, most common value, or some clustering or regression approach\n",
    "   - `fillna()`\n",
    "   - Other imputer\n",
    "\n",
    "Let's see where we have nulls in our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1d0fc462201245bc69ce4b4a95e3a17",
     "grade": false,
     "grade_id": "cell-f752502496d9ef37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          0\n",
       "Sex          0\n",
       "ChestPain    0\n",
       "RestBP       0\n",
       "Chol         0\n",
       "Fbs          0\n",
       "RestECG      0\n",
       "MaxHR        0\n",
       "ExAng        0\n",
       "Oldpeak      0\n",
       "Slope        0\n",
       "Ca           3\n",
       "Thal         1\n",
       "AHD          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum(axis=0) #sum along first dimension/axis, so, indexed by 0 (axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2a00ef57a330269b3a9cb26863e431f",
     "grade": false,
     "grade_id": "cell-76325bb0d88ba514",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Imputation for Continuous\n",
    "\n",
    "Looks like we are missing a few values for both a continuous (`Ca`) and categorical (`Thal`) value.  The following cells impute our numeric data, using the `median`.\n",
    "\n",
    "Now, it actually turns out that `Ca` is really categorical, but we'll get the same result whether we use the median (0) or most frequent value (0), so for the sake of practice we will treat it as continuous in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b37c904c9b37a6cbe6e62147acc7b05",
     "grade": false,
     "grade_id": "cell-406043d46a0ecaa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  RestBP   Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  Slope   Ca\n",
       "0  56.0  0.0   140.0  294.0  0.0      2.0  153.0    0.0      1.3    2.0  0.0\n",
       "1  44.0  1.0   120.0  169.0  0.0      0.0  144.0    1.0      2.8    3.0  0.0\n",
       "2  42.0  1.0   130.0  180.0  0.0      0.0  150.0    0.0      0.0    1.0  0.0\n",
       "3  40.0  1.0   152.0  223.0  0.0      0.0  181.0    0.0      0.0    1.0  0.0\n",
       "4  63.0  0.0   135.0  252.0  0.0      2.0  172.0    0.0      0.0    1.0  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's fill with SimpleImputer:\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_continuous = SimpleImputer(strategy='median')\n",
    "\n",
    "#Restrict to only the numeric data types:\n",
    "train_numeric = train_df.select_dtypes(include=[np.number])\n",
    "\n",
    "#Can fit transform on the training data:\n",
    "impute_results = imputer_continuous.fit_transform(train_numeric)\n",
    "\n",
    "#We get a numpy array as output\n",
    "\n",
    "#Convert to dataframe:\n",
    "train_numeric = pd.DataFrame(impute_results, columns = train_numeric.columns,\n",
    "                              index = train_numeric.index)\n",
    "\n",
    "#We got?\n",
    "train_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7417b95abfb0f622827ce8d021ede1b",
     "grade": false,
     "grade_id": "cell-55825a21c34e0073",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age        0\n",
       "Sex        0\n",
       "RestBP     0\n",
       "Chol       0\n",
       "Fbs        0\n",
       "RestECG    0\n",
       "MaxHR      0\n",
       "ExAng      0\n",
       "Oldpeak    0\n",
       "Slope      0\n",
       "Ca         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that it worked?\n",
    "train_numeric.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca0f084f809a1b7bdd35a9e1745ea567",
     "grade": false,
     "grade_id": "cell-a4a3e84b283e71ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 1.</font>\n",
    "\n",
    "\n",
    "## Now, do it for the categorical data\n",
    "\n",
    "Following the steps for numeric data, create a DataFrame named `train_categorical` that consists of the three categorical columns of type `object`, i.e. `ChestPain`, `Thal`, and `AHD`. Use `SimpleImputer` to impute any missing values, using the `most_frequent` strategy.\n",
    "\n",
    "Your end result should be a **DataFrame** named `train_categorical` that has no null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60c910a45fdeb4318fc7015340a51fac",
     "grade": false,
     "grade_id": "cell-38ac9d31d90b1e27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "train_categorical = train_df[['ChestPain', 'Thal', 'AHD']]\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "train_categorical_imputed = imputer.fit_transform(train_categorical)\n",
    "\n",
    "train_categorical = pd.DataFrame(train_categorical_imputed, columns=['ChestPain', 'Thal', 'AHD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42cec6457b0bfbed77297ade501c7ea1",
     "grade": true,
     "grade_id": "cell-6265e5bf16e6bca2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether train_categorical is pandas DataFrame\n",
    "assert isinstance(train_categorical, pd.core.frame.DataFrame)\n",
    "\n",
    "## test whether train_categorical has the correct shape\n",
    "assert train_categorical.shape == (212, 3)\n",
    "\n",
    "## test whether train_categorical has any NaNs\n",
    "assert train_categorical.isna().sum().sum() == 0\n",
    "\n",
    "## test whether there are 114 instances of \"normal\" in column \"Thal\"\n",
    "assert (train_categorical.Thal == 'normal').sum() == 114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "481e9a6c3f701e254474af9e102e8375",
     "grade": false,
     "grade_id": "cell-a099c0849342fe5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Get everything back together\n",
    "\n",
    "Let's put everything back in the new DataFrame `train_df_filled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40d9a82befeb0e65b39a5627d6e917ea",
     "grade": false,
     "grade_id": "cell-74b7f9bc9e1fefb5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>152.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>135.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex     ChestPain  RestBP   Chol  Fbs  RestECG  MaxHR  ExAng  \\\n",
       "0  56.0  0.0    nontypical   140.0  294.0  0.0      2.0  153.0    0.0   \n",
       "1  44.0  1.0  asymptomatic   120.0  169.0  0.0      0.0  144.0    1.0   \n",
       "2  42.0  1.0    nonanginal   130.0  180.0  0.0      0.0  150.0    0.0   \n",
       "3  40.0  1.0  asymptomatic   152.0  223.0  0.0      0.0  181.0    0.0   \n",
       "4  63.0  0.0    nonanginal   135.0  252.0  0.0      2.0  172.0    0.0   \n",
       "\n",
       "   Oldpeak  Slope   Ca        Thal  AHD  \n",
       "0      1.3    2.0  0.0      normal   No  \n",
       "1      2.8    3.0  0.0       fixed  Yes  \n",
       "2      0.0    1.0  0.0      normal   No  \n",
       "3      0.0    1.0  0.0  reversable  Yes  \n",
       "4      0.0    1.0  0.0      normal   No  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put back into our train_df, which we'll now call train_df_filled:\n",
    "#######\n",
    "train_df_filled = train_df.copy()\n",
    "\n",
    "train_df_filled[train_numeric.columns] = train_numeric[train_numeric.columns]\n",
    "train_df_filled[train_categorical.columns] = train_categorical[train_categorical.columns]\n",
    "\n",
    "train_df_filled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "444c10e6b9db2cf6cc69187044f40c4f",
     "grade": false,
     "grade_id": "cell-8942659b9ace93e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Confirm that there are no NaNs in the DataFrame (note if the sum is not 0, you must have done something wrong in creating `train_categorical`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c47bfbc7e4195d0327d6100d70463d7d",
     "grade": false,
     "grade_id": "cell-7c8b9af5c4e18b3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This should be 0 if all went right\n",
    "train_df_filled.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f39afd536c983dd13560385f82f89d9f",
     "grade": false,
     "grade_id": "cell-7135e7b6a17429bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Note: Check the proportions of our labels:\n",
    "\n",
    "Let's see the proportions of labels (Yes/No) in `AHD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7322c84fa69bd6a181f174778611f750",
     "grade": false,
     "grade_id": "cell-916b226d859b9184",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.54717\n",
       "Yes    0.45283\n",
       "Name: AHD, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Relative frequency of No and Yes in the training data\n",
    "## Data is fairly balanced\n",
    "train_df_filled['AHD'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e4b7f59c3828d43fdaa93dcb7140b32",
     "grade": false,
     "grade_id": "cell-fb9bcdad8fdb716e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fit Naive Bayes Using the training data\n",
    "\n",
    "\n",
    "Now, let's construct a model and fit it on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f077c203fbfafb526fd36ca798f34e9",
     "grade": false,
     "grade_id": "cell-5989bfa17397d9d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Create the Naive Bayes model\n",
    "\n",
    "<br>\n",
    "\n",
    "First, we create pandas **DataFrame** `X_train` and  pandas **Series** `y_train`. The DataFrame `X_train` should consist of only features/predictors of the training data, not the output `AHD`, while `y_train` should consist of the corresponding labels (i.e. column `AHD`) of the training data.\n",
    "\n",
    "After creation, we print out the first couple of observations for both objects to check that everything seems okay (sanity check)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b1f254999c8ab0ab66ed85dac6d1d46",
     "grade": false,
     "grade_id": "cell-237cab196f564fe4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>152.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>135.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex     ChestPain  RestBP   Chol  Fbs  RestECG  MaxHR  ExAng  \\\n",
       "0  56.0  0.0    nontypical   140.0  294.0  0.0      2.0  153.0    0.0   \n",
       "1  44.0  1.0  asymptomatic   120.0  169.0  0.0      0.0  144.0    1.0   \n",
       "2  42.0  1.0    nonanginal   130.0  180.0  0.0      0.0  150.0    0.0   \n",
       "3  40.0  1.0  asymptomatic   152.0  223.0  0.0      0.0  181.0    0.0   \n",
       "4  63.0  0.0    nonanginal   135.0  252.0  0.0      2.0  172.0    0.0   \n",
       "\n",
       "   Oldpeak  Slope   Ca        Thal  \n",
       "0      1.3    2.0  0.0      normal  \n",
       "1      2.8    3.0  0.0       fixed  \n",
       "2      0.0    1.0  0.0      normal  \n",
       "3      0.0    1.0  0.0  reversable  \n",
       "4      0.0    1.0  0.0      normal  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     No\n",
       "1    Yes\n",
       "2     No\n",
       "3    Yes\n",
       "4     No\n",
       "Name: AHD, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Our training X and training y\n",
    "####\n",
    "\n",
    "X_train = train_df_filled.iloc[:,:-1]\n",
    "y_train = train_df_filled['AHD']\n",
    "\n",
    "\n",
    "display(X_train.head())\n",
    "\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d89c4288be4aa7e218170689832a675",
     "grade": false,
     "grade_id": "cell-439c40f6c10cf49e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 2.</font>\n",
    "\n",
    "Now, create pandas DataFrame `X_test` and pandas Series `y_test`. The DataFrame `X_test` should consist of all the features/predictors values from the test data (without output `AHD`). The `y_test` Series should consist of just the output values (i.e. labels) from the test data.\n",
    "\n",
    "**Remember you need to first impute missing values, *using the imputers fit to the training data*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a179cb4090983d3641c3afe9351cd044",
     "grade": false,
     "grade_id": "cell-1cb60ddcb1d92cf1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
    "X_train_numeric = X_train[numeric_columns]\n",
    "X_test_numeric = X_test[numeric_columns]\n",
    "# Initialize and apply the StandardScaler to the numeric data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_numeric)\n",
    "X_test = scaler.transform(X_test_numeric)\n",
    "\n",
    "if not isinstance(X_test, pd.core.frame.DataFrame):\n",
    "    X_test = pd.DataFrame(X_test_scaled, columns=numeric_columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47c1a6e6222d7216003569f9b0907e7b",
     "grade": true,
     "grade_id": "cell-8db4b73afd0125f9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-f7c498c6cfb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## test whether X_test is pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## test whether the first 4 values of column Age are correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m47\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## test whether X_test is pandas DataFrame\n",
    "assert isinstance(X_test, pd.core.frame.DataFrame)\n",
    "\n",
    "## test whether the first 4 values of column Age are correct\n",
    "assert sum(X_test['Age'].iloc[:4] != [47, 55, 66, 42]) == 0\n",
    "\n",
    "## test whether the first 4 values of column ChestPain are correct\n",
    "assert sum(X_test['ChestPain'].iloc[:4] != ['nonanginal','asymptomatic','typical','typical']) == 0\n",
    "\n",
    "## test whether the first 4 values of column Chol are correct\n",
    "assert np.linalg.norm(np.array(X_test['Chol'].iloc[:4]) - np.array([243, 353, 226, 244]), ord=2) < 1.e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a74b644d8bda4325ecfc46d0b34e92a",
     "grade": true,
     "grade_id": "cell-07bc6494bc101311",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-99ece8158b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## test whether y_test is a pandas Series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## test that first 4 and last 4 values of y_test are correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## test whether y_test is a pandas Series\n",
    "assert isinstance(y_test, pd.core.series.Series)\n",
    "\n",
    "\n",
    "## test that first 4 and last 4 values of y_test are correct\n",
    "assert sum(y_test.iloc[:4] != ['Yes', 'Yes', 'No', 'No']) == 0\n",
    "assert sum(y_test.iloc[-4:] != ['Yes', 'No', 'No','No']) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e8d3c0f187d763ab1363ccfbe04d778",
     "grade": false,
     "grade_id": "cell-2f2f838b8503afa6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Encoding and training\n",
    "\n",
    "To prepare for training, we encode our training labels (`y_train`) to either a numeric 0 or 1 (Bernoulli random variable, or binary encoding), and also use a numpy array instead of a pandas Series. The 0-1 coded values are stored in the variable `y_train_int`.\n",
    "\n",
    "One way to do this is with a little list comprehension\n",
    "\n",
    "`y_train_int = np.array([int(train_y[i]=='Yes') for i in range(len(train_y))])`\n",
    "\n",
    "Or like this:\n",
    "\n",
    "`y_train_int = (y_train == 'Yes').astype(int).values`\n",
    "\n",
    "However, we will demonstrate the `LabelEncoder()` function from `sklearn.preprocessing` submodule.\n",
    "\n",
    "We'll go ahead and also create `y_test_int` in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24782a964f8049b6becc2b927fc25f97",
     "grade": false,
     "grade_id": "cell-f68c9a6c6eca8572",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#0-1 encoding train labels\n",
    "y_train_int = LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "#Do for the testing set too:\n",
    "y_test_int = LabelEncoder().fit_transform(y_test)\n",
    "\n",
    "y_train_int[:5] #print first 5 of y_train_int (check that No=0, Yes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84563397200b46c60151926c404acd45",
     "grade": false,
     "grade_id": "cell-bccdb4639a3249d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "### Naive Bayes with mixed variables\n",
    "\n",
    "In our dataset `Heart` we have both discrete and continuous features. Submodule `sklearn.naive_bayes` does not handle this situation very well automatically. There are several ways to proceed, each simplifying the situation. One way is to bin/bucketize the numerical features. That is, for each numerical feature, we group its values into bins, and each bin is represented by a single number from 0, 1, ... , n, where n is the number of bins (i.e. categories) for this feature.\n",
    "\n",
    "To do this, then, we need to first bucketize each numeric feature. We'll use a custom transformer for this.\n",
    "\n",
    "Then we use the `OrdinalEncoder` function from the submodule `sklearn.preprocessing` for categorical variables that are objects.\n",
    "\n",
    "The following series of cells creates `X_train_prepared`, which has binned versions of the continuous variables, and encoded versions of the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "216e67fdee795572651c4fe06c469d94",
     "grade": false,
     "grade_id": "cell-cd28735aa7477bc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##Let's make a custom transformer for binning/bucketizing\n",
    "#########\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_array\n",
    "\n",
    "class QuantileBucketer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_quantiles=10, random_state=42):\n",
    "        self.num_quantiles = num_quantiles\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        #Extract feature names from columns:\n",
    "        if (isinstance(X, pd.DataFrame)):\n",
    "            self.feature_names = np.array(X.columns)\n",
    "        #If no columns, just 0 through n\n",
    "        else:\n",
    "            self.feature_names = np.array(range(0, X.shape[1])).astype(str)\n",
    "\n",
    "        \n",
    "        #Bucketize the data\n",
    "        \n",
    "        X = check_array(X)\n",
    "        \n",
    "        #Go through each column:\n",
    "        #Will have list of lists for the bins:\n",
    "        self.bins_ = []\n",
    "        \n",
    "        #Do a quantile cut\n",
    "        for i in range(np.shape(X)[1]):\n",
    "            X_bucket, bins = pd.qcut(X[:,i],\n",
    "                                 q=self.num_quantiles, labels=False, retbins=True, duplicates='drop')\n",
    "\n",
    "            #Save the bins\n",
    "            #We need to make sure all the testing data will go into a bin, so set the left and right limits to -/+ infinitiy\n",
    "            bins[0] = -np.inf\n",
    "            bins[len(bins)-1] = np.inf\n",
    "            \n",
    "            self.bins_.append(bins)\n",
    "        \n",
    "        return self #Always return self\n",
    "\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        X = check_array(X)\n",
    "        \n",
    "        #Cut the variables based on the buckets trained in the fit\n",
    "        for i in range(np.shape(X)[1]):\n",
    "            X[:, i] = pd.cut(X[:,i], bins=self.bins_[i], labels=False)\n",
    "            \n",
    "        #Return bucketized X:\n",
    "        return X\n",
    "\n",
    "\n",
    "    def get_feature_names_out(self, names=None):\n",
    "        #Just return the feature names used to create:\n",
    "        return self.feature_names\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3607303821af9147d6df6bc8bddf1891",
     "grade": false,
     "grade_id": "cell-0d1d710975eff06e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##Our continuous columns for binning:\n",
    "##Note that some of the numeric are actually categorical already:\n",
    "##We'll bucket into 10 quantiles, if possible\n",
    "bucket = QuantileBucketer(num_quantiles=10)\n",
    "\n",
    "bucket_cols = ['Age', 'RestBP', 'Chol', 'MaxHR', 'Oldpeak']\n",
    "\n",
    "#We're going to cheat a little and train on all the data so that the whole range is included:\n",
    "#bucket.fit(pd.concat((X_train[bucket_cols], X_test[bucket_cols])))\n",
    "bucket.fit(X_train[bucket_cols])\n",
    "\n",
    "\n",
    "#Make X_train_prepared as follows:\n",
    "X_train_prepared = X_train.copy()\n",
    "X_train_prepared[bucket_cols] = bucket.transform(X_train[bucket_cols])\n",
    "\n",
    "#What we got?\n",
    "X_train_prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01bf15d06ed4bb9cdaa878cb4deca8a7",
     "grade": false,
     "grade_id": "cell-899e66659c57b436",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Create an OrdinalEncoder for ChestPain and Thal:\n",
    "#######\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "#And encode!\n",
    "X_train_prepared[['ChestPain', 'Thal']] = ord_enc.fit_transform(X_train_prepared[['ChestPain', 'Thal']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a18971c6cdc4a6f320c08a1c494b4c1",
     "grade": false,
     "grade_id": "cell-a59caa70b6bb9c42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##Result?\n",
    "\n",
    "X_train_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5100352a6444a83e93cc5386ebe1a087",
     "grade": false,
     "grade_id": "cell-7a27feeeb1658fa2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 3.</font>\n",
    "\n",
    "\n",
    "## Create `X_test_prepared`\n",
    "\n",
    "Use the bucket transformer and ordinal encoder created in the above cells to create `X_test_prepared`. You should use the same binning scheme and ordinal encoding as for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65aeaeb0d87d7954946d6506566cf44a",
     "grade": false,
     "grade_id": "cell-8a062c2febc52253",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ade24d25180565c6b301800e16b5fea",
     "grade": true,
     "grade_id": "cell-fd5a0bcb554e97b1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether X_test_prepared is pandas DataFrame\n",
    "assert isinstance(X_test_prepared, pd.core.frame.DataFrame)\n",
    "\n",
    "## test whether the first 4 values of column Age are correct\n",
    "assert sum(X_test_prepared['Age'].iloc[:4] != [2, 4, 8, 0]) == 0\n",
    "\n",
    "## test whether the first 4 values of column ChestPain are correct\n",
    "assert sum(X_test_prepared['ChestPain'].iloc[:4] != [1, 0, 3, 3]) == 0\n",
    "\n",
    "## test whether the first 4 values of column Chol are correct\n",
    "assert np.linalg.norm(np.array(X_test_prepared['Chol'].iloc[:4]) - np.array([5, 9, 3, 5]), ord=2) < 1.e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "298e50f50e726c7782cbcb5d8f975da2",
     "grade": false,
     "grade_id": "cell-5652fc14d51f0f42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Creating and fitting the model\n",
    "\n",
    "We use the `CategoricalNB()` function from `sklearn.naive_bayes` submodule, which requires encoding, which is why we did the previous step.  We can create and train as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e9d3d01ff619c316523e8248c8849ad",
     "grade": false,
     "grade_id": "cell-254101028af64501",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = CategoricalNB()  #create model object\n",
    "model.fit(X_train_prepared, y_train_int) # fit on train data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4f967fc19f914d4f8705743e4448a5c",
     "grade": false,
     "grade_id": "cell-628b0cee72b5ff4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Predicting\n",
    "\n",
    "To measure performance, we should use test data. That will be your job in a moment. However, here, we make predictions for each training observation. Again, this is not as reliable estimate of true performance as when test data are used. The main purpose of using training rather than test data is to ensure the model did reasonably on in-sample data, and as a model for making prediction on test data (out-of-sample).\n",
    "\n",
    "**Note**: As the model has been specifically constructed to minimize error with respect to the training data, we are vulnerable to overfitting (recall the **bias-variance tradeoff** phenomenon). As the notion of bias-variance tradeoff suggests, at some point a better fit to training data implies worse performance on other possible datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf9aae8011d40cb188e8cbab9a439011",
     "grade": false,
     "grade_id": "cell-daf6dd7c3232d187",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "yhat_train = model.predict(X_train_prepared) # predict on train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3802fad8dfe2ff74151ffb46772bc3b4",
     "grade": false,
     "grade_id": "cell-7ed8ae41b9852bca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "To assess performance, we can take a look at confusion matrix for the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89241411e2560ca658dca5287237d425",
     "grade": false,
     "grade_id": "cell-e0657706d86a7d80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## confusion matrix using pandas method crosstab\n",
    "pd.crosstab(y_train, yhat_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8699c815f61a2fb8784c8027010a743",
     "grade": false,
     "grade_id": "cell-4c540a01d6da7325",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Alternative way, just using scikit-learn's confusion_matrix function:\n",
    "confusion_matrix(y_train_int, yhat_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3dfa4871f4641aab363f5195ffa6338",
     "grade": false,
     "grade_id": "cell-59df0f8af32ba61a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that the accuracy score, i.e. the proportion of correctly predicted outputs is ${103+78 \\over103+13+18+78} \\approx 85.38\\%$. \n",
    "\n",
    "**Caveat** Due to bias-variance tradeoff, we know that this reasonably high score does not necessarily guarantee a good prediction on new (out-of-sample) data. It might be just due to overfitting - i.e. if the model is too flexible, it will easily fit the train data very well. Again, good performance on out-of-sample data are not guaranteed. This is the reason why we want to test performance on new data (test data), that were not used for fitting the model.\n",
    "\n",
    "The accuracy score can also be computed using `accuracy_score()` function from the `sklearn.matrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9be864bd9f3084e7f2bb8b3ef6b2cd38",
     "grade": false,
     "grade_id": "cell-733ce6d707f3d029",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_train_int, yhat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8b62994ba0fce84306d94f8ce30ea9e",
     "grade": false,
     "grade_id": "cell-6b086c30841eb759",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 4.</font>\n",
    "\n",
    "\n",
    "Using the `X_test_prepared` DataFrame and `y_test_int` array from above, create predictions for the testing dataset.\n",
    "\n",
    "Create array `yhat_test`, using the model trained on training data, and the processed feature values for the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0c61dc021f0eac430fd2b719375a2fa",
     "grade": false,
     "grade_id": "cell-e5ee8ea0538354f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "277bdce6cfa3dddb88395aba132f4b3c",
     "grade": true,
     "grade_id": "cell-48c53b5c3949dd8f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether first 10 values of column yhat_test are correct\n",
    "assert sum(yhat_test[:10] != [0, 1, 1, 0, 0, 0, 1, 1, 0, 0]) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b513a903ae732d0079b69c90db313b23",
     "grade": false,
     "grade_id": "cell-525ab3c23dfe4538",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 5.</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "Compute the confusion matrix (for test data) and store it as a variable `cm`.\n",
    "\n",
    "**Hint**: the entry in the 1st row and 1st column (predicted value=No, actual AHD value=No) should be 45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "650795ba05f30e52e9159b6a540d93a5",
     "grade": false,
     "grade_id": "cell-b666156bc5aa3ca3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "629799fb940c4737a4a48a203d99f32c",
     "grade": true,
     "grade_id": "cell-3515257552ee3a3f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## check whether the determinant of the confusion matrix is 1503\n",
    "\n",
    "assert abs(np.linalg.det(np.array(cm)) - 1503) < 1.e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad5de73b40f8622205ab7fcfd66e589c",
     "grade": true,
     "grade_id": "cell-6b1813e4500d6e13",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## check whether the answer is correct (hidden test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18617d3a43a6dfeb21bd2de6f881bd0a",
     "grade": false,
     "grade_id": "cell-f05f3f1839276a14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 6.</font>\n",
    "\n",
    "#### Accuracy Score\n",
    "\n",
    "Compute the accuracy score, i.e. the proportion of the correctly predicted outputs. Store this value as python variable `acc`. So, your answer should look like\n",
    "\n",
    "`acc = <some expression>`\n",
    "\n",
    "Do **NOT** round your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ddef2b9585594f43dc9698b3cff9abe",
     "grade": false,
     "grade_id": "cell-2b6ed741785681ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57eb6ced8395ab2e4f98dbd9121a1514",
     "grade": true,
     "grade_id": "cell-8b8e2d39b2a89a27",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether 4th and 5th decimal digits of acc are 13\n",
    "\n",
    "assert np.mod(int(np.floor(acc * 10**5)), 100) == 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a674e78cc3df2034c0c1a607635fd435",
     "grade": true,
     "grade_id": "cell-1f88f04dadc8165a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether acc is correct (hidden tests)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75c5e7ef481be6d23ce86a4e55c41c30",
     "grade": false,
     "grade_id": "cell-db18cc72ce0db2e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "**Remark**\n",
    "\n",
    "If you got `acc` right, you will notice that the accuracy score using test data is actually slightly higher than for the training data. While it is possible (depending on randomization of training and test samples) that the accuracy score will happen to be higher when measured on test data than on train data, on average, it is expected to be lower on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4a66c18f264920c86d9ad014154d3a6",
     "grade": false,
     "grade_id": "cell-c087f8166912dfc4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 7.</font>\n",
    "\n",
    "### TPR and TNR (Sensitivity and Specificity)\n",
    "\n",
    "Now, let us calculate the true positive rate (TPR, also known as the sensitivity or the recall), and the true negative rate (TNR, also known as specificity).  The former gives us the probability that, in this case, given angiographic heart disease is present, our model correctly gives us a positive.  The latter gives the probability that our model returns a negative result, given that angiographic heart disease is absent.\n",
    "\n",
    "We can calculate these quantities as follows:\n",
    "\n",
    "$$\n",
    "\\text{Sensitivity = TPR = } \\frac{\\text{TP}}{\\text{TP + FN}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Specificity = TNR = } \\frac{\\text{TN}}{\\text{TN + FP}}\n",
    "$$\n",
    "\n",
    "Do so, and assign your answers to the variables `TPR` and `TNR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f79d0a2d4effceab5d0658fa880f8c1b",
     "grade": false,
     "grade_id": "cell-daebc620b157539b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7dcd41a08e4aa20acab231d4ab81ece0",
     "grade": true,
     "grade_id": "cell-28876814045c2bd2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the 2nd and 3rd decimal digits of TPR are 90\n",
    "\n",
    "assert np.mod(int(np.floor(TPR * 10**3)), 100) == 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "459a37e30ff90040e06733ad0684e7e6",
     "grade": true,
     "grade_id": "cell-5a78b086cebb2ef6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the 2nd and 3rd decimal digits of TNR are 37\n",
    "\n",
    "assert np.mod(int(np.floor(TNR * 10**3)), 100) == 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb97ddb6232518b26e256231f2d6144d",
     "grade": true,
     "grade_id": "cell-089050219d1a5054",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether TPR and TNR are correct (hidden tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd80e2c0ee189228c32eb697ba0aca64",
     "grade": false,
     "grade_id": "cell-c2484705c8c3802b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 8.</font>\n",
    "\n",
    "## Precision/Recall and the F1 Score\n",
    "\n",
    "Calculate and report the precision (positive predictive value), recall (sensitivity), and F1 score (harmonic mean of precision and recall) for the model on testing data.\n",
    "\n",
    "Assign your answers to the variables `precision`, `recall`, and `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48a2cf23ca75f1611a5fd65202756b7a",
     "grade": false,
     "grade_id": "cell-18d4174622c432bc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61a3b79f3d77de59f470abfdb4eaf703",
     "grade": true,
     "grade_id": "cell-dcf8af29b9009ee8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the 2nd and 3rd decimal digits of precision are 18\n",
    "\n",
    "assert np.mod(int(np.floor(precision * 10**3)), 100) == 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abc93463b2bf585821d2b4bd571ce6fb",
     "grade": true,
     "grade_id": "cell-d9d1b58f09e8315a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the 2nd and 3rd decimal digits of recall are 90\n",
    "\n",
    "assert np.mod(int(np.floor(recall * 10**3)), 100) == 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e668e2c3f33757e07aaf2ae7f79e8455",
     "grade": true,
     "grade_id": "cell-aecf42b694c5b379",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the 2nd and 3rd decimal digits of f1_score are 50\n",
    "\n",
    "assert np.mod(int(np.floor(f1 * 10**3)), 100) == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9491cb7348e96e9ae47e212eb4c1c436",
     "grade": true,
     "grade_id": "cell-e2b1c11f9ecde171",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether precision, reall, and f1_score are correct (hidden tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "835eb88ab42d81808672b5065a5a542d",
     "grade": false,
     "grade_id": "cell-702184aca608c6ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 9.</font>\n",
    "\n",
    "## ROC Curve\n",
    "\n",
    "Construct ROC curves summarizing model performance on both the training and testing datasets. Your result should mimic the following:\n",
    "\n",
    "<img src=\"ROC_Bayes.png\" alt=\"ROC Curve\" style=\"width:600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3723af86f5342d464ffbd9cce707933a",
     "grade": true,
     "grade_id": "cell-8d6ab6779496694a",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad923e3c0b03b9a7d655412abbade77c",
     "grade": false,
     "grade_id": "cell-fa8ee675c5523a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 10.</font>\n",
    "\n",
    "## Precision-Recall Curve\n",
    "\n",
    "Construct Precision-Recall curves summarizing model performance on both the training and testing datasets. Your result should mimic the following:\n",
    "\n",
    "<img src=\"PR_Bayes.png\" alt=\"PR Curve\" style=\"width:600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e147872664ed2c9d4679de2d708d1890",
     "grade": true,
     "grade_id": "cell-cfece69471485a7f",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "907f7d38b9782abbef499c1ec0e8dd88",
     "grade": false,
     "grade_id": "cell-15771410cdaecf07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART 2: KNN Regression/Classification in Python + Hyperparameter Tuning\n",
    "\n",
    "\n",
    "In this part of the homework, we'll train KNN regression and classification models in Python, as well as find the best value for $k$, the number of nearest neighbors, using functions available through scikit-learn.\n",
    "\n",
    "Run the following cell to import some more libraries/objects that we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77c73a2546490026918b3ea456e5c9a4",
     "grade": false,
     "grade_id": "cell-124611e3b6c74d60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Some helper functions to split and scale our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#KNN Classifier and Regression models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#Allows us to exhaustively search for best hyperparameter using cross-validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1f617bb5e883d04b99979af6cc6bd57",
     "grade": false,
     "grade_id": "cell-9173f3652c36cee1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## PART 2A. KNN Regression\n",
    "\n",
    "Now, let's load the `Maricopa_AQ.csv` dataset: This gives mean daily values of the four so-called critera gases, O$_3$, NO$_2$, SO$_2$, and CO, in Maricopa county from 2000 to 2016. Filtered down from original dataset available at https://www.kaggle.com/datasets/sogun3/uspollution, itself scraped from the EPA Air Quality System (https://www.epa.gov/aqs).\n",
    "\n",
    "Our output variable will be `NO2 Mean`, while our predictors will be, **in this exact order in our DataFrame,** `O3 Mean`, `SO2 Mean`, and `CO Mean`. Run the following cell to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08fd6995d6c7068fc581b20364c4b99c",
     "grade": false,
     "grade_id": "cell-ffc5cec9eebeecd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Maricopa_AQ.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf30cc8c77b948fe69c59a4ab71bf747",
     "grade": false,
     "grade_id": "cell-8d8ef1ed38324238",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 1.</font>\n",
    "\n",
    "### Train/Test Split\n",
    "\n",
    "- Use Scikit-learn's `train_test_split` function to give a simple randomized split. Do the following:\n",
    "\n",
    "1. Set the random state to $42$\n",
    "2. Hold back 30% of the data for testing\n",
    "\n",
    "**Create the following variables:**\n",
    "\n",
    "1. `X_train`\n",
    "2. `X_test`\n",
    "3. `y_train`\n",
    "4. `y_test`\n",
    "\n",
    "Your inputs (features, predictors) should be, **in this exact order in the DataFrame**\n",
    "\n",
    "`O3 Mean`, `SO2 Mean`, and `CO Mean`\n",
    "\n",
    "Your output (target) should be:\n",
    "\n",
    "`NO2 Mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43269f1efbf7955cbcc4acb68f63e24a",
     "grade": false,
     "grade_id": "cell-3b2744f2cf6051c0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78cc1cdeabd8c063ca76cda579c94b1d",
     "grade": true,
     "grade_id": "cell-fa915d584108eba4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the first 2 rows of X_train are correct:\n",
    "c = np.array([[0.014333, 1.818182, 1.155556],\n",
    "       [0.030625, 3.291667, 1.216667]])\n",
    "\n",
    "assert np.isclose(X_train.iloc[:2,:].values, c).sum() == 6\n",
    "\n",
    "## test whether the first 2 rows of y_train are correct:\n",
    "assert np.isclose(y_train[:2].values, np.array([29.136364, 26.625])).sum() == 2\n",
    "\n",
    "\n",
    "c = np.array([[0.031167, 1.25    , 0.420833],\n",
    "       [0.014792, 3.416667, 1.4125  ]])\n",
    "\n",
    "## test whether the first 2 rows of X_test are correct:\n",
    "assert np.isclose(X_test.iloc[:2,:].values, c).sum() == 6\n",
    "\n",
    "## test whether the first 2 rows of y_test are correct:\n",
    "assert np.isclose(y_test[:2].values, np.array([15.75, 34.541667])).sum() == 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea21b37d65e2ae58ca6da70ec40de579",
     "grade": false,
     "grade_id": "cell-4384efe245a8c6c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 2.</font>\n",
    "\n",
    "### Rescale the Data\n",
    "\n",
    "Note that the scales for our predictor values are quite different. Therefore, it is usually advisable to rescale data. We can rescale any feature to have mean 0 and unit variance with the operation\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma},\n",
    "$$\n",
    "where $\\mu$ and $\\sigma$ are the mean and standard deviation of the feature $x$, respectively.  We can either do this manually, or we can use `StandardScaler` from scikit-learn.\n",
    "\n",
    "Use `StandardScaler()` to rescale your `X_train` and `X_test` variables. Note once again that you should *fit* the scaler to the `X_train` data (not the whole dataset, and not the test dataset), then use the fitted scaler to transform both the `X_train` and `X_test` variables.\n",
    "\n",
    "Simply leave `X_train` and `X_test` and numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd4ae16f0f76696c029d80cdef396253",
     "grade": false,
     "grade_id": "cell-92787110b003054a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e14ee90ab4d8f136d5a845b67a9feea6",
     "grade": true,
     "grade_id": "cell-b7d4045f57594ea1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the first 2 rows of (scaled) X_train are correct:\n",
    "c = np.array([[-0.83998391,  0.10125774,  1.50787084],\n",
    "       [ 0.60829962,  1.2631331 ,  1.66856412]])\n",
    "\n",
    "assert (np.isclose(X_train[:2,:],c)).sum() == 6\n",
    "\n",
    "\n",
    "c = np.array([[ 0.65648092, -0.34676627, -0.42410626],\n",
    "       [-0.79918093,  1.36169836,  2.18351312]])\n",
    "\n",
    "## test whether the first 2 rows of (scaled) X_test are correct:\n",
    "assert (np.isclose(X_test[:2,:],c)).sum() == 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "807e95d382ffaf2d836d8e683643f0f5",
     "grade": false,
     "grade_id": "cell-c91de8466672da36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 3.</font>\n",
    "\n",
    "### Use GridSearchCV to Find Optimal Hyperparameter $k$/`n_neighbors` for a KNN Regressor\n",
    "\n",
    "We wish to train a `KNeighborsRegressor` on this data, but choose an optimal hyperparameter `n_neighbors`. Use the Scikit-learn `GridSearchCV()` object to evaluate a `KNeighborsRegressor()` model performance using k-folds cross-validation for $k$ (`n_neighbors`) between 1 and 100, inclusive, and with 10 folds.\n",
    "\n",
    "Create a `GridSearchCV` object named `grid_search` and train it on your (scaled) training data.\n",
    "\n",
    "<br>\n",
    "\n",
    "Once you've fit `grid_search`, plot the mean score function ($R^2$ by default) across folds against the number of neighbors. You will need to use results found in `grid_search.cv_results_`.  Your plot should resemble:\n",
    "\n",
    "<img src=\"k_curve.png\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccebf12a1512dbdd5045f6e118e0d4c9",
     "grade": true,
     "grade_id": "cell-640f47f98f370c53",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2728ab02b93c514aa6ac32469842a1d",
     "grade": false,
     "grade_id": "cell-7b564cc69b6bde37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "Now, extract the best `n_neighbors` parameter from `grid_search`, and assign this (integer) to the variable `k_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c96ca2a5899f5b911d4a849a676cde1",
     "grade": false,
     "grade_id": "cell-d4344186fc049454",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d449fa29e489ec32eff38ca2074f6431",
     "grade": true,
     "grade_id": "cell-335b39c807160fce",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the k_best is between 30 and 40\n",
    "\n",
    "assert ((30 <= k_best) and (40 >= k_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ad172b2dc8e9d1549c2fe10f457be5d",
     "grade": true,
     "grade_id": "cell-cc1b527a803ae699",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## check whether k_best is correct (hidden test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6de858bdee6a821baae1c5dd28099561",
     "grade": false,
     "grade_id": "cell-c3dd87ebfd680143",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 4.</font>\n",
    "\n",
    "### Train Model, Predict\n",
    "\n",
    "Create a `KNeighborsRegressor` model object named `knn_model` with `n_neighbors` set to the `k_best` you found above, and fit the model using your training dataset.\n",
    "\n",
    "Once you've trained your model, make predictions for your test dataset. Store the predicted values in the variable `test_preds`. This should be a `numpy` array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "230c7586840f12f34cdc2617ed911ecf",
     "grade": false,
     "grade_id": "cell-08cad326881067a9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df12344d26568a3c86ef6a800f2ccdee",
     "grade": true,
     "grade_id": "cell-6e68d6cf85d41ff9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the first 5 entries of test_preds are correct:\n",
    "\n",
    "assert np.isclose(test_preds[:5], np.array([18.95303884, 37.14603256, 19.27508081,  9.98867597, 20.96954184])).sum() == 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd9eabde91e238dbfad8824a80eac737",
     "grade": false,
     "grade_id": "cell-aeec0564e6c7eb84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 5.</font>\n",
    "\n",
    "### Plot Performance\n",
    "\n",
    "Plot predicted vs. actual output for your test data.  That is, to get a visual sense of how well the model performed, one can plot the predicted vs. true values. Perfect predictions should fall on straight line with slope 1.\n",
    "\n",
    "Make such a plot (with appropriate labels, etc.), which should resemble the following:\n",
    "\n",
    "<img src=\"y_vs_y.png\" style=\"width:475px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f912b8afc64e4476d4ae83e44e30e557",
     "grade": true,
     "grade_id": "cell-ed5bc0329ea1db8d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "843abb094f571df609865dc5347c267f",
     "grade": false,
     "grade_id": "cell-313493094c9c0ade",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## PART2B. KNN Classification\n",
    "\n",
    "Now, let's train a KNN Classifer, using the `houseliving.csv` dataset, already introduced in class. Our output variable will be `house`, which is $1$ if the respondent owns their house, and $0$ else. Our predictors will be, **in this exact order in our DataFrame,** `salary` and `age`.\n",
    "\n",
    "Run the cell below to import the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69ed562f1a4eaf920be4ba12a92df225",
     "grade": false,
     "grade_id": "cell-26443f064f61e200",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('houseliving.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7853631603cd2b5fa3e7e0afb9d9e3fc",
     "grade": false,
     "grade_id": "cell-968522ccaff08b95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Also note the balance of house values:\n",
    "##\n",
    "\n",
    "df['house'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fee5718097622bfa6ae3c56ec83f217",
     "grade": false,
     "grade_id": "cell-99f788d59c2f6afe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 6.</font>\n",
    "\n",
    "### Train/Test Split Once Again\n",
    "\n",
    "Once again, use Scikit-learn's `train_test_split` function to give a simple randomized split. Do the following:\n",
    "\n",
    "1. Set the random state to $42$\n",
    "2. Hold back 30% of the data for testing\n",
    "\n",
    "**Create the following variables:**\n",
    "\n",
    "1. `X_train`\n",
    "2. `X_test`\n",
    "3. `y_train`\n",
    "4. `y_test`\n",
    "\n",
    "Your inputs (features, predictors) should be, **in this exact order in the DataFrame**\n",
    "\n",
    "`salary` and `age`\n",
    "\n",
    "Your output (target) should be:\n",
    "\n",
    "`housing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "594a620412d9d0775c3411afd75d3cd2",
     "grade": false,
     "grade_id": "cell-d79e2259c4612c53",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c250045a297e68f512bcb39c7dc371c",
     "grade": true,
     "grade_id": "cell-c53406694c377030",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the first 2 rows of X_train are correct:\n",
    "c = np.array([[3.3000e+04, 4.6000e+01],\n",
    "       [4.8695e+04, 4.1000e+01]])\n",
    "\n",
    "assert np.isclose(X_train.iloc[:2,:].values, c).sum() == 4\n",
    "\n",
    "## test whether the first 10 rows of y_train are correct:\n",
    "assert np.isclose(y_train[:10].values, np.array([0, 0, 0, 1, 0, 0, 1, 1, 1, 0])).sum() == 10\n",
    "\n",
    "\n",
    "c = np.array([[9.8305e+04, 3.9000e+01],\n",
    "       [2.7000e+04, 4.3000e+01]])\n",
    "\n",
    "## test whether the first 2 rows of X_test are correct:\n",
    "assert np.isclose(X_test.iloc[:2,:].values, c).sum() == 4\n",
    "\n",
    "## test whether the first 10 rows of y_testn are correct:\n",
    "assert np.isclose(y_test[:10].values, np.array([0, 0, 1, 1, 0, 0, 1, 1, 0, 1])).sum() == 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a66d3f11908f8179ab9d97b68ee70eb",
     "grade": false,
     "grade_id": "cell-95ce2e90fb760b14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 7.</font>\n",
    "\n",
    "### Rescale the Data\n",
    "\n",
    "Again, as before, use `StandardScaler` to rescale your `X_train` and `X_test` variables. Note that you should *fit* the scaler to the `X_train` data (not the whole dataset, and not the test dataset), then use the fitted scaler to transform both the `X_train` and `X_test` variables.\n",
    "\n",
    "This time, **assign the scaled variables to `X_train_scaled` and `X_test_scaled`**. We want to preserve our original DataFrames for plotting below.\n",
    "\n",
    "Leave `X_train` and `X_test` and numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14772dd4e757ac6c59743edd2f912a73",
     "grade": false,
     "grade_id": "cell-20677b398c1f2bf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88217ff07ff3b881c5aa0fb44ff3bc4b",
     "grade": true,
     "grade_id": "cell-a8bd41831fd062e3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the first 2 rows of X_train_scaled are correct:\n",
    "c = np.array([[-1.07742064, -0.04976943],\n",
    "       [-0.65707682, -0.51053802]])\n",
    "\n",
    "assert (np.isclose(X_train_scaled[:2,:],c)).sum() == 4\n",
    "\n",
    "\n",
    "c = np.array([[ 0.67157924, -0.69484546],\n",
    "       [-1.23811276, -0.32623059]])\n",
    "\n",
    "## test whether the first 2 rows of X_test_scaled are correct:\n",
    "assert (np.isclose(X_test_scaled[:2,:],c)).sum() == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf7e73aeee58735d433f0e29a18368b8",
     "grade": false,
     "grade_id": "cell-c1ebb6881b127c2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 8.</font>\n",
    "\n",
    "### Use GridSearchCV to Find Optimal Hyperparameter\n",
    "\n",
    "Use the scikit-learn `GridSearchCV` object to evaluate the model using k-folds cross-validation for $k$ (`n_neighbors`) between **1 and 50**, inclusive, and with **5 folds**.\n",
    "\n",
    "This time, you must pass `KNeighborsClassifier()` to `GridSearchCV()` (NOT `KNeighborsRegressor`). Use your *scaled* training data to determine the optimal `n_neighbors` hyperparameter.\n",
    "\n",
    "Assign the best value of `n_neighbors` to the variable `k_best`, as an **integer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a414a531a0a70904d91efb461d4197",
     "grade": false,
     "grade_id": "cell-67e75cb7121568f1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ecd3eb03d52f30b069530095b1ab2c4",
     "grade": true,
     "grade_id": "cell-b7b256d5c2c8c1e2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the k_best is between 40 and 50\n",
    "\n",
    "assert ((40 <= k_best) and (50 >= k_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c89774e5b2668d7cb8505bc2b8b49583",
     "grade": true,
     "grade_id": "cell-76ed6abf4957c969",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## check whether k_best is correct (hidden test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5dca170d3de04219ed5612ce63c50416",
     "grade": false,
     "grade_id": "cell-09f237b8b961d59f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 9.</font>\n",
    "\n",
    "### Train Model, Predict\n",
    "\n",
    "Create a `KNeighborsClassifier` model object named `knn_model` with `n_neighbors` set to `k_best` determined above, and fit the model using your scaled training dataset.\n",
    "\n",
    "**Name your model `classifier`.**\n",
    "\n",
    "Once you've trained your model, make predictions for your test dataset. Store the predicted values in the variable `test_preds`. This should be a `numpy` array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8bb9e14b1bbfb7ce697e1d38d68c572",
     "grade": false,
     "grade_id": "cell-2d4f18533ef8e296",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "930b69910f18e23db311c994a5cfe91d",
     "grade": true,
     "grade_id": "cell-81a14ef043aca438",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the model `classifier` exists:\n",
    "assert (classifier)\n",
    "\n",
    "## and that it is of the correct type:\n",
    "assert type(classifier) == sklearn.neighbors._classification.KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4aee3007ff518bf004d8a0b3cb298684",
     "grade": true,
     "grade_id": "cell-5024f655bd290288",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether the first 15 entries of test_preds are correct:\n",
    "\n",
    "assert np.isclose(test_preds[:15], np.array([0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0])).sum() == 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e64ea52cf17090e2551db0b4a23441d7",
     "grade": false,
     "grade_id": "cell-40602054568b3e90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 10.</font>\n",
    "\n",
    "### Characterize Accuracy\n",
    "\n",
    "Determine the following metrics, using the test dataset, and assign them to the indicated variables:\n",
    "\n",
    "1. The accuracy: `acc`\n",
    "2. Sensitivity (True Positive Rate): `TPR`\n",
    "3. Specificity (True Negative Rate): `FPR`\n",
    "\n",
    "You may find `accuracy_score` and `confusion_matrix` from `sklearn.metrics` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7104e67ffd727786973dce6e1ba12b3b",
     "grade": false,
     "grade_id": "cell-26e21f0ae4d4bc02",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "246fc47a40af101fd32bf6eec84ccc8e",
     "grade": true,
     "grade_id": "cell-848c49b026642f28",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether 4th and 5th decimal digits of acc are 77\n",
    "assert np.mod(int(np.floor(acc * 10**5)), 100) == 77\n",
    "\n",
    "## test whether 4th and 5th decimal digits of TPR are 36\n",
    "assert np.mod(int(np.floor(TPR * 10**5)), 100) == 36\n",
    "\n",
    "## test whether 4th and 5th decimal digits of TNR are 50\n",
    "assert np.mod(int(np.floor(TNR * 10**5)), 100) == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6c57e2dffdeb944cf5aa42f7db76e9a",
     "grade": true,
     "grade_id": "cell-aece7c5076c19520",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether acc is correct (hidden tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "499c21c3fa381857b85e1bc6a710e76b",
     "grade": true,
     "grade_id": "cell-994ec34026ad4e23",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether TPR is correct (hidden tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a88718dee5ec634340ca81191e178e25",
     "grade": true,
     "grade_id": "cell-cd196cc82ec5475a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## test whether TNR is correct (hidden tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbd999a9565642c2911dded74854efcd",
     "grade": false,
     "grade_id": "cell-015fe5461a9313e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"color: red\">Question 10.</font>\n",
    "\n",
    "### Plot Results\n",
    "\n",
    "Create a contour plot to demonstrate the area that is predicted by the model to give `house = 0` vs `house = 1`, along with the testing data. Color testing data points by their true `house` value (not predicted). Your plot should resemble the following:\n",
    "\n",
    "<img src=\"knn_classifier_surface.png\" style=\"width: 475px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac2a6a75093be2be435829584c5096da",
     "grade": true,
     "grade_id": "cell-a600ed10b6a821a4",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
